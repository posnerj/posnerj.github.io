<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Dr. Jonas Posner </title> <meta name="author" content="Jonas Posner"> <meta name="description" content="Publications by categories in reversed chronological order."> <meta name="keywords" content="Jonas Posner, HPC, Supercomputing, AMT"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://posnerj.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <title>Publications | Dr. Jonas Posner</title> <meta name="generator" content="Jekyll v4.4.1"> <meta property="og:title" content="Publications"> <meta property="og:locale" content="en"> <meta name="description" content="Publications by categories in reversed chronological order."> <meta property="og:description" content="Publications by categories in reversed chronological order."> <link rel="canonical" href="https://posnerj.github.io/publications/"> <meta property="og:url" content="https://posnerj.github.io/publications/"> <meta property="og:site_name" content="Dr. Jonas Posner"> <meta property="og:type" content="website"> <meta name="twitter:card" content="summary"> <meta property="twitter:title" content="Publications"> <script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Publications by categories in reversed chronological order.","headline":"Publications","url":"https://posnerj.github.io/publications/"}</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Dr. Jonas Posner </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">Talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Curriculum Vitae </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">Publications by categories in reversed chronological order.</p> </header> <article> <div class="publications"> <a id="Journal Articles"></a> <p class="bibtitle">Journal Articles</p> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="FinnertyMalleableSNCS24" class="col-sm-8"> <div class="title">On the Performance of Malleable APGAS Programs and Batch Job Schedulers</div> <div class="author"> Patrick Finnerty, <em>Jonas Posner</em>, Janek Bürger, Leo Takaoka, and Takuma Kanzaki </div> <div class="periodical"> <em>Springer Nature Computer Science</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1007/s42979-024-02641-7" rel="external nofollow noopener" target="_blank">10.1007/s42979-024-02641-7 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:0EnyYjriUFMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Malleability—the ability for applications to dynamically adjust their resource allocations at runtime—presents great potential to enhance the efficiency and resource utilization of modern supercomputers. However, applications are rarely capable of growing and shrinking their number of nodes at runtime, and batch job schedulers provide only rudimentary support for such features. While numerous approaches have been proposed to enable application malleability, these typically focus on iterative computations and require complex code modifications. This amplifies the challenges for programmers, who already wrestle with the complexity of traditional MPI inter-node programming. Asynchronous Many-Task (AMT) programming presents a promising alternative. In AMT, computations are split into many fine-grained tasks, which are processed by workers. This makes transparent task relocation via the AMT runtime system possible, thus offering great potential for enabling efficient malleability. In this work, we propose an extension to an existing AMT system, namely APGAS for Java. We provide easy-to-use malleability programming abstractions, requiring only minor application code additions from programmers. Runtime adjustments, such as process initialization and termination, are automatically managed by our malleability extension. We validate our malleability extension by adapting a load balancing library handling multiple benchmarks. We show that both shrinking and growing operations cost low execution time overhead. In addition, we demonstrate compatibility with potential batch job schedulers by developing a protoannote batch job scheduler that supports malleable jobs. Through extensive real-world job batches execution on up to 32 nodes, involving rigid, moldable, and malleable programs, we evaluate the impact of deploying malleable APGAS applications on supercomputers. Exploiting scheduling algorithms, such as FCFS, Backfilling, Easy-Backfilling, and one exploiting malleable jobs, the experimental results highlight a significant improvement regarding several metrics for malleable jobs. We show a 13.09% makespan reduction (the time needed to schedule and execute all jobs), a 19.86% increase in node utilization, and a 3.61% decrease in job turnaround time (the time a job takes from its submission to completion) when using 100% malleable job in combination with our protoannote batch job scheduler compared to the best-performing scheduling algorithm with 100% rigid jobs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FinnertyMalleableSNCS24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Finnerty, Patrick and Posner, Jonas and B\"urger, Janek and Takaoka, Leo and Kanzaki, Takuma}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Performance of Malleable APGAS Programs and Batch Job Schedulers}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Springer Nature Computer Science}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s42979-024-02641-7}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{0EnyYjriUFMC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerCheckpointingIJNC22" class="col-sm-8"> <div class="title">Task-Level Resilience: Checkpointing vs. Supervision</div> <div class="author"> <em>Jonas Posner</em>, Lukas Reitz, and Claudia Fohry </div> <div class="periodical"> <em>Special Issue International Journal of Networking and Computing (IJNC)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.15803/ijnc.12.1_47" rel="external nofollow noopener" target="_blank">10.15803/ijnc.12.1_47 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:_FxGoFyzp5QC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> With the advent of exascale computing, issues such as application irregularity and permanent hardware failure are growing in importance. Irregularity is often addressed by task-based parallel programming implemented with work stealing. At the task level, resilience can be provided by two principal approaches, namely checkpointing and supervision. For both, particular algorithms have been worked out recently. They perform local recovery and continue the program execution on a reduced set of resources. The checkpointing algorithms regularly save task descriptors explicitly, while the supervision algorithms exploit their natural duplication during work stealing and may be coupled with steal tracking to minimize the number of task re-executions. Thus far, the two groups of algorithms have been targeted at different task models: checkpointing algorithms at dynamic independent tasks, and supervision algorithms at nested fork-join programs. This paper transfers the most advanced supervision algorithm to the dynamic independent tasks model, thus enabling a comparison between checkpointing and supervision. Our comparison includes experiments, running time predictions, and simulations of job set executions. Results consistently show typical resilience overheads below 1% for both approaches. The overheads are lower for supervision in practically relevant cases, but checkpointing takes over for order millions of processes. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PosnerCheckpointingIJNC22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Reitz, Lukas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Task-Level Resilience: Checkpointing vs. Supervision}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Special Issue International Journal of Networking and Computing (IJNC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{47--72}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.15803/ijnc.12.1_47}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{_FxGoFyzp5QC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerFaultToleranceFGCS19" class="col-sm-8"> <div class="title">A Comparison of Application-Level Fault Tolerance Schemes for Task Pools</div> <div class="author"> <em>Jonas Posner</em>, Lukas Reitz, and Claudia Fohry </div> <div class="periodical"> <em>Future Generation Computer Systems (FGCS)</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1016/j.future.2019.11.031" rel="external nofollow noopener" target="_blank">10.1016/j.future.2019.11.031 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Fault tolerance is an important requirement for successful program execution on exascale systems. The common approach, checkpointing, regularly saves a program’s state, such that the execution can be restarted after permanent node failures. Checkpointing is often performed on system level, but its deployment on application level can reduce the running time overhead. The drawback of application-level checkpointing is a higher programming expense. It pays off if the checkpointing is applied to reusable patterns. We consider task pools, which exist in many variants. The paper supposes that tasks are generated dynamically and are free of side effects. Further, the final result must be computed from individual task results by reduction. Moreover, the pools must be distributed with private queues, and adopt work stealing. The paper describes and evaluates three application-level fault tolerance schemes for task pools. All use uncoordinated checkpointing and regularly save information in a resilient store. The first scheme (called AllFT) saves descriptors of all open tasks; the second scheme (called IncFT) selectively and incrementally saves only part of them; and the third scheme (called LogFT) logs stealing events and writes checkpoints in parallel to task processing. All schemes have been implemented by extending the Global Load Balancing (GLB) library of the “APGAS for Java” programming system. In experiments with the UTS, NQueens, and BC benchmarks with up to 672 workers, the running time overhead during failure-free execution, compared to a non-resilient version of GLB, was typically below 6%. The recovery cost was negligible, and there was no clear winner among the three schemes. A more detailed performance analysis with synthetic benchmarks revealed that IncFT and LogFT are superior in scenarios with large task descriptors. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PosnerFaultToleranceFGCS19</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Reitz, Lukas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Comparison of Application-Level Fault Tolerance Schemes for Task Pools}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Future Generation Computer Systems (FGCS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{105}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{119--134}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.future.2019.11.031}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Tyk-4Ss8FVUC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerHybridSuper18" class="col-sm-8"> <div class="title">Hybrid Work Stealing of Locality-Flexible and Cancelable Tasks for the APGAS Library</div> <div class="author"> <em>Jonas Posner</em>, and Claudia Fohry </div> <div class="periodical"> <em>The Journal of Supercomputing</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1007/s11227-018-2234-8" rel="external nofollow noopener" target="_blank">10.1007/s11227-018-2234-8 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:IjCSPb-OGe4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Since large parallel machines are typically clusters of multicore nodes, parallel programs should be able to deal with both shared memory and distributed memory. This paper proposes a hybrid work stealing scheme, which combines the lifeline-based variant of distributed task pools with the node-internal load balancing of Java’s Fork/Join framework. We implemented our scheme by extending the APGAS library for Java, which is a branch of the X10 project. APGAS programmers can now spawn locality-flexible tasks with a new asyncAny construct. These tasks are transparently mapped to any resource in the overall system, so that the load is balanced over both nodes and cores. Unprocessed asyncAny-tasks can also be cancelled. In performance measurements with up to 144 workers on up to 12 nodes, we observed near linear speedups for four benchmarks and a low overhead for cancellation-related bookkeeping. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PosnerHybridSuper18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hybrid Work Stealing of Locality-Flexible and Cancelable Tasks for the APGAS Library}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Journal of Supercomputing}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1435--1448}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s11227-018-2234-8}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{IjCSPb-OGe4C}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerFaultToleranceIJNC18" class="col-sm-8"> <div class="title">A Java Task Pool Framework providing Fault-Tolerant Global Load Balancing</div> <div class="author"> <em>Jonas Posner</em>, and Claudia Fohry </div> <div class="periodical"> <em>Special Issue on the International Journal of Networking and Computing (IJNC)</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.15803/ijnc.8.1_2" rel="external nofollow noopener" target="_blank">10.15803/ijnc.8.1_2 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:eQOLeE2rZwMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Fault tolerance is gaining importance in parallel computing, especially on large clusters. Traditional approaches handle the issue on system-level. Application-level approaches are becoming increasingly popular, since they may be more efficient. This paper presents a fault-tolerant work stealing technique on application level, and describes its implementation in a generic reusable task pool framework for Java. When using this framework, programmers can focus on writing sequential code to solve their actual problem. The framework is written in Java and utilizes the APGAS library for parallel programming. It implements a comparatively simple algorithm that relies on a resilient data structure for storing backups of local pools and other information. Our implementation uses Hazelcast’s IMap for this purpose, which is an automatically distributed and fault-tolerant key-value store. The number of backup copies is configurable and determines how many simultaneous failures can be tolerated. Our algorithm is shown to be correct in the sense that failures are either tolerated and the computed result is the same as in non-failure case, or the program aborts with an error message. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PosnerFaultToleranceIJNC18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Java Task Pool Framework providing Fault-Tolerant Global Load Balancing}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Special Issue on the International Journal of Networking and Computing (IJNC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2--31}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.15803/ijnc.8.1_2}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{eQOLeE2rZwMC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="FohryFaultToleranceSCPE15" class="col-sm-8"> <div class="title">Fault Tolerance Schemes for Global Load Balancing in X10</div> <div class="author"> Claudia Fohry, Marco Bungart, and <em>Jonas Posner</em> </div> <div class="periodical"> <em>Scalable Computing: Practice and Experience (SCPE)</em>, 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.12694/scpe.v16i2.1088" rel="external nofollow noopener" target="_blank">10.12694/scpe.v16i2.1088 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Scalability postulates fault tolerance to be efficient. One approach handles permanent node failures at user level. It is supported by Resilient X10, a Partitioned Global Address Space language that throws an exception when a place fails. We consider task pools, which are a widely used pattern for load balancing of irregular applications, and refer to the variant that is implemented in the Global Load Balancing framework GLB of X10. Here, each worker maintains a private pool and supports cooperative work stealing. Victim selection and termination detection follow the lifeline scheme. Tasks may generate new tasks dynamically, are free of side-effects, and their results are combined by reduction. We consider a single worker per node, and assume that failures are rare and uncorrelated. The paper introduces two fault tolerance schemes. Both are based on regular backups of the local task pool contents, which are written to the main memory of another worker and updated in the event of stealing. The first scheme mainly relies on synchronous communication. The second scheme deploys asynchronous communication, and significantly improves on the first scheme efficiency and robustness. Both schemes have been implemented by extending the GLB source code. Experiments were run with the Unbalanced Tree Search (UTS) and Betweenness Centrality benchmarks. For UTS on 128 nodes, for instance, we observed an overhead of about 81% with the synchronous scheme and about 7% with the asynchronous scheme. The protocol overhead for a place failure was negligible. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FohryFaultToleranceSCPE15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fohry, Claudia and Bungart, Marco and Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fault Tolerance Schemes for Global Load Balancing in X10}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scalable Computing: Practice and Experience (SCPE)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{169--186}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.12694/scpe.v16i2.1088}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{2osOgNQ5qMEC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <a id="Dissertation"></a> <p class="bibtitle">Dissertation</p> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerPhD22" class="col-sm-8"> <div class="title">Load Balancing, Fault Tolerance, and Resource Elasticity for Asynchronous Many-Task Systems</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>University of Kassel, Germany</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.17170/kobra-202207286542" rel="external nofollow noopener" target="_blank">10.17170/kobra-202207286542 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:hqOjcs7Dif8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> High-Performance Computing (HPC) enables solving complex problems from various scientific fields including key societal problems such as COVID-19. Recently, traditional simulations have been joined by more diverse workloads, including irregular ones limiting the predictability of the computations. Workloads are run on HPC machines that comprise an increasing number of hardware components, and serve multiple users simultaneously. To enable efficient and productive programming of today’s HPC machines and beyond, it is essential to address a variety of issues, including: load balancing (i.e., utilizing all resources equally), fault tolerance (i.e., coping with hardware failures), and resource elasticity (i.e., allowing the addition/release of resources). In this thesis, we address these issues in the context of Asynchronous Many-Task (AMT) programming. In AMT, programmers split a computation into many fine-grained execution units (called tasks), which are dynamically mapped to processing units (e.g., threads) by a runtime system. While AMT is becoming established for single computers, we are focusing on cluster AMTs, which are currently merely protoannotes with limited functionalities. Regarding load balancing, we propose a work stealing technique that transparently schedules tasks to resources of the overall system, balancing the workload over all processing units. In this context, we introduce several tasking constructs. Experiments show good scalability, and a productivity evaluation shows intuitive use. Regarding fault tolerance, we propose four techniques to protect programs transparently. All perform localized recovery and continue the program execution with fewer resources. Three techniques write uncoordinated checkpoints in a resilient store: One saves descriptors of all open tasks; the second saves only part of them; and the third logs stealing events to reduce the number of checkpoints. The fourth technique does not write checkpoints at all, but exploits natural task duplication of work stealing. Experiments show no clear winner between the techniques. For instance, the first one has a failure-free running time overhead below 1% and a recovery overhead below 0.5 seconds, both for smooth weak caling. Simulations of job set executions show that the completion time can be reduced by up to 97%. Regarding resource elasticity, we propose a technique to enable the addition and release of nodes at runtime by transparently relocating tasks accordingly. Experiments show costs for adding and releasing nodes below 0.5 seconds. Additionally, simulations of job set executions show that the completion time can be reduced by up to 20%. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">PosnerPhD22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Load Balancing, Fault Tolerance, and Resource Elasticity for Asynchronous Many-Task Systems}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{University of Kassel, Germany}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.17170/kobra-202207286542}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{hqOjcs7Dif8C}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <a id="Conference and Workshop Articles"></a> <p class="bibtitle">Conference and Workshop Articles</p> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="DPPvsAPGASWAMTA25" class="col-sm-8"> <div class="title">Dynamic Resource Management: Comparison of Asynchronous Many-Task (AMT) and Dynamic Processes with PSets (DPP)</div> <div class="author"> <em>Jonas Posner</em>, Nick Bietendorf, Dominik Huber, Martin Schreiber, and Martin Schulz </div> <div class="periodical"> <em>In Workshop on Asynchronous Many-Task Systems and Applications (WAMTA)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.5281/zenodo.14902214" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="abstract hidden"> <p> Dynamic resource management allows programs running on supercomputers to adjust resource allocations at runtime. This dynamism offers potential improvements in both individual program efficiency and overall supercomputer utilization. Despite growing interest in recent years, the adoption of dynamic resource management remains limited due to inadequate support from widely used resource managers, such as Slurm, and programming environments, such as MPI. Furthermore, developing flexible programs introduces substantially higher programming complexity compared to static programs. While recent research has improved MPI’s resource flexibility, significant programmability challenges remain. Additionally, MPI-based solutions rely on low-level message-passing primitives, which are particularly challenging to use for non-iterative workloads. Asynchronous Many-Task (AMT) programming offers a promising alternative to MPI. By decomposing computations into tasks that are dynamically scheduled by the runtime system, AMT is well suited to handling irregular and dynamic workloads. AMT’s transparent resource management is ideal for dynamic resources, allowing the runtime system to seamlessly redistribute tasks in response to node changes without requiring additional programmer effort. In this work, we compare the “Dynamic Processes with PSets (DPP)” design principle implemented in an MPI-based environment and the APGAS+GLB AMT runtime system. We implement benchmarks in both environments to evaluate programmability and perform experiments on up to 16 nodes to analyze the performance of static and flexible programs. Results demonstrate that GLB simplifies programming with built-in load balancing and resource flexibility. In contrast, the MPI-DPP implementation achieves superior performance in handling node changes but at the cost of increased programming complexity. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DPPvsAPGASWAMTA25</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Bietendorf, Nick and Huber, Dominik and Schreiber, Martin and Schulz, Martin}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Dynamic Resource Management: Comparison of Asynchronous Many-Task (AMT) and Dynamic Processes with PSets (DPP)}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Workshop on Asynchronous Many-Task Systems and Applications (WAMTA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerEvolvingDynRes24" class="col-sm-8"> <div class="title">The Impact of Evolving APGAS Programs on HPC Clusters</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>In Proceedings Euro-Par Parallel Processing Workshops (DynResHPC)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.5281/zenodo.13378632" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://easychair.org/publications/preprint/7Rwf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Preprint</a> </div> <div class="abstract hidden"> <p> High-performance computing (HPC) clusters are traditionally managed statically, i.e., user jobs maintain a fixed number of computing nodes for their entire execution. This approach becomes inefficient with the increasing prevalence of dynamic and irregular workloads, which have unpredictable computation patterns that result in fluctuating resource needs at runtime. For instance, nodes cannot be released when they are not needed, limiting the overall supercomputer performance. However, the realization of jobs that can grow and shrink their number of node allocations at runtime is hampered by a lack of support in both resource managers and programming environments. This work leverages evolving programs that grow and shrink autonomously through automated decision-making, making them well-suited for dynamic and irregular workloads. The Asynchronous Many-Task (AMT) programming model has recently shown promise in this context. In AMT, computations are decomposed into many fine-grained tasks, enabling the runtime system to transparently migrate these tasks across nodes. Our study builds on the APGAS AMT runtime system, which supports evolving capabilities, i.e., handles process initialization and termination automatically and requires only minimal user code additions. We enable communication between APGAS and a prototype resource manager as well as extend the Easy-Backfilling job scheduling algorithm to support evolving jobs. We conduct extensive real-world job batch executions on 10 nodes—involving a mix of rigid, moldable, and evolving programs—to evaluate the impact of evolving APGAS programs on supercomputers. Our experimental results demonstrate a 23% reduction in job batch makespan and a 29% reduction in job turnaround time for evolving jobs. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerEvolvingDynRes24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Impact of Evolving APGAS Programs on HPC Clusters}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings Euro-Par Parallel Processing Workshops (DynResHPC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerEvolvingWAMTA24" class="col-sm-8"> <div class="title">Evolving APGAS Programs: Automatic and Transparent Resource Adjustments at Runtime</div> <div class="author"> <em>Jonas Posner</em>, Raoul Goebel, and Patrick Finnerty </div> <div class="periodical"> <em>In Proceedings Workshop on Asynchronous Many-Task Systems and Applications (WAMTA)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1007/978-3-031-61763-8_15" rel="external nofollow noopener" target="_blank">10.1007/978-3-031-61763-8_15 </a> <a href="https://doi.org/10.5281/zenodo.10671344" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:MXK_kJrjxJIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> In the rapidly evolving field of High-Performance Computing (HPC), the need for resource elasticity is paramount, particularly in addressing the dynamic nature of irregular computational workloads. A key area of elasticity lies within programming models that typically offer limited support. Fully elastic programs are both malleable—capable of dynamically adjusting resources in response to external job scheduler requests—and evolving—autonomously deciding when and how to adjust resources, e.g., through automated decision-making. Previous elasticity approaches typically relied on iterative workloads and required complex code modifications. Asynchronous Many-Task (AMT) programming is emerging as a powerful alternative. In AMT, computations are split into fine-grained tasks, allowing transparent task relocation by the runtime system and unlocking significant potential for efficient elasticity. This work-in-progress proposes an extension to the existing AMT APGAS that recently incorporated malleability. Our extension adds evolving capabilities providing automatic and transparent resource adjustments to meet changing computational workloads at runtime. Our easy-to-use abstractions require only minimal code additions; adjustments such as process initialization and termination are managed automatically. Our extension is validated via a load-balancing library for irregular workloads. We propose two heuristics for automatic computational load detection: one that uses CPU loads provided by the operating system, and another that exploits detailed insights into task loads. We evaluate our approach using a novel synthetic benchmark that starts with a single task evolving into two irregular trees connected by a long sequential branch. Preliminary results are promising, indicating that both the CPU-based heuristic and the task-based heuristic showing similar efficiency.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerEvolvingWAMTA24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Goebel, Raoul and Finnerty, Patrick}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Evolving APGAS Programs: Automatic and Transparent Resource Adjustments at Runtime}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings Workshop on Asynchronous Many-Task Systems and Applications (WAMTA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-61763-8_15}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{MXK_kJrjxJIC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerSchedulingPECS23" class="col-sm-8"> <div class="title">Enhancing Supercomputer Performance with Malleable Job Scheduling Strategies</div> <div class="author"> <em>Jonas Posner</em>, Fabian Hupfeld, and Patrick Finnerty </div> <div class="periodical"> <em>In Proceedings Euro-Par Parallel Processing Workshops (PECS)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1007/978-3-031-48803-0_14" rel="external nofollow noopener" target="_blank">10.1007/978-3-031-48803-0_14 </a> <a href="https://doi.org/10.5281/zenodo.8315842" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:MXK_kJrjxJIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> In recent years, supercomputers have experienced significant advancements in performance and have grown in size, now comprising several thousands nodes. To unlock the full potential of these machines, efficient resource management and job scheduling—assigning parallel programs to nodes—are crucial. Traditional job scheduling approaches employ rigid jobs that use the same set of resources throughout their lifetime, resulting in significant resource under-utilization. By employing malleable jobs that are capable of changing their number of resources during execution, the performance of supercomputers has potential to increase. However, designing algorithms for scheduling malleable jobs is challenging since it requires complex strategies to determine when and how to reassign resources among jobs while maintaining fairness. In this work, we extend a recently proposed malleable job scheduling algorithm by introducing new strategies. Specifically, we propose three priority orders to determine which malleable job to consider for resource reassignments and the number of nodes when starting a job. Additionally, we propose three reassignment approaches to handle the delay between scheduling decisions and the actual transfer of resources between jobs. This results in nine algorithm variants. We then evaluate the impact of deploying malleable jobs scheduled by our nine algorithm variants. For that, we simulate the scheduling of job sets containing varying proportions of rigid and malleable jobs on a hypothetical supercomputer. The results demonstrate significant improvements across several metrics. For instance, with 20% of malleable jobs, the overall completion time is reduced by 11% while maintaining high node utilization and fairness. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerSchedulingPECS23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Hupfeld, Fabian and Finnerty, Patrick}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhancing Supercomputer Performance with Malleable Job Scheduling Strategies}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings Euro-Par Parallel Processing Workshops (PECS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-48803-0_14}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{MXK_kJrjxJIC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="FinnertyMalleableAMTE24" class="col-sm-8"> <div class="title">Malleable APGAS Programs and their Support in Batch Job Schedulers</div> <div class="author"> Patrick Finnerty, Reo Takaoka, Takuma Kanzaki, and <em>Jonas Posner</em> </div> <div class="periodical"> <em>In Proceedings Euro-Par Parallel Processing Workshops (AMTE)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1007/978-3-031-48803-0_8" rel="external nofollow noopener" target="_blank">10.1007/978-3-031-48803-0_8 </a> <a href="https://doi.org/10.5281/zenodo.8287393" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:8k81kl-MbHgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Malleability—the ability for applications to dynamically adjust their resource allocations at runtime—presents great potential to enhance the efficiency and resource utilization of modern supercomputers. However, applications are rarely capable of growing and shrinking their number of nodes at runtime, and batch job schedulers provide only rudimentary support for these features. While numerous approaches have been proposed for enabling application malleability, these typically focus on iterative computations and require complex code modifications. This amplifies the challenges for programmers, who already wrestle with the complexity of traditional MPI inter-node programming. Asynchronous Many-Task (AMT) programming presents a promising alternative. Computations are split into many fine-grained tasks, which are processed by workers. This way, AMT enables transparent task relocation via the runtime system, thus offering great potential for efficient malleability. In this paper, we propose an extension to an existing AMT system, namely APGAS for Java, that provides easy-to-use malleability. More specifically, programmers enable application malleability with only minimal code additions, thanks to the simple abstractions we provide. Runtime adjustments, such as process initialization and termination, are automatically managed. We demonstrate the ease of integration between our extension and future batch job schedulers through the implementation of a simplistic malleable batch job scheduler. Additionally, we validate our extension through the adaption of a load balancing library handling multiple benchmarks. Finally, we show that even a simplistic scheduling strategy for malleable applications improves resource utilization, job throughput, and overall job response time. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FinnertyMalleableAMTE24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Finnerty, Patrick and Takaoka, Reo and Kanzaki, Takuma and Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Malleable APGAS Programs and their Support in Batch Job Schedulers}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings Euro-Par Parallel Processing Workshops (AMTE)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-48803-0_8}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{8k81kl-MbHgC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerElasticityP2S221" class="col-sm-8"> <div class="title">Transparent Resource Elasticity for Task-Based Cluster Environments with Work Stealing</div> <div class="author"> <em>Jonas Posner</em>, and Claudia Fohry </div> <div class="periodical"> <em>In Proceedings International Conference on Parallel Processing (ICPP) Workshops (P2S2)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1145/3458744.3473361" rel="external nofollow noopener" target="_blank">10.1145/3458744.3473361 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:Se3iqnhoufwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Resource elasticity allows to dynamically change the resources of running jobs, which may significantly improve the throughput on supercomputers. Elasticity requires support from both job schedulers and user applications. Whereas the adaptation of traditional programs requires additional programmer effort, task-based programs can be made elastic in a transparent way. In this paper, we propose a corresponding technique for implementation in a runtime system. We refer to a work stealing-based runtime for clusters, which uses the lifeline scheme for victim selection, combines inter-node work stealing with intra-node work sharing, and handles dynamic independent tasks, i.e., tasks that may spawn child tasks but do not otherwise cooperate. We experimentally assess the elasticity overhead of our scheme and find that adding/releasing up to 64 nodes takes less than 0.5 seconds. This value is determined with the help of a new formula that estimates the overhead-free running time of work-stealing programs with a changing number of workers. Using this result, we then quantify the gain of deploying elastic jobs. For that, we simulate the execution of job sets that contain some percentage of elastic jobs on two hypothetical supercomputers. We use an existing elastic job scheduler, which we concretize, e.g. by a new heuristic to determine the minimum, maximum, and preferred number of nodes for a job. Results show that the makespan can be reduced by up to 20% if most jobs are elastic. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerElasticityP2S221</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Transparent Resource Elasticity for Task-Based Cluster Environments with Work Stealing}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings International Conference on Parallel Processing (ICPP) Workshops (P2S2)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--10}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3458744.3473361}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Se3iqnhoufwC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerCheckpointingAPDCM21" class="col-sm-8"> <div class="title">Checkpointing vs. Supervision Resilience Approaches for Dynamic Independent Tasks</div> <div class="author"> <em>Jonas Posner</em>, Lukas Reitz, and Claudia Fohry </div> <div class="periodical"> <em>In Proceeding International Parallel and Distributed Processing Symposium (IPDPS) Workshops (APDCM)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1109/IPDPSW52791.2021.00089" rel="external nofollow noopener" target="_blank">10.1109/IPDPSW52791.2021.00089 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:LkGwnXOMwfcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> With the advent of exascale computing, issues such as application irregularity and permanent hardware failure are growing in importance. Irregularity is often addressed by task-based parallel programming coupled with work stealing. At the task level, resilience can be provided by two principal approaches, namely checkpointing and supervision. For both, particular algorithms have been worked out recently. They perform local recovery and continue the program execution on a reduced set of resources. The checkpointing algorithms regularly save task descriptors explicitly, while the supervision algorithms exploit their natural duplication during work stealing and may be coupled with steal tracking to minimize the number of task re-executions. Thus far, the two groups of algorithms have been targeted at different task models: checkpointing algorithms at dynamic independent tasks, and supervision algorithms at nested fork-join programs.This paper transfers the most advanced supervision algorithm to the dynamic independent tasks model, thus enabling a comparison between checkpointing and supervision. Our comparison includes experiments and running time predictions. Results consistently show typical resilience overheads below 1% for both approaches. The overheads are lower for supervision in practically relevant cases, but checkpointing takes over for order millions of processes. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerCheckpointingAPDCM21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Reitz, Lukas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Checkpointing vs. Supervision Resilience Approaches for Dynamic Independent Tasks}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceeding International Parallel and Distributed Processing Symposium (IPDPS) Workshops (APDCM)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IPDPSW52791.2021.00089}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{LkGwnXOMwfcC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerDMTCPCluster20" class="col-sm-8"> <div class="title">System-Level vs. Application-Level Checkpointing</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>In International Conference on Cluster Computing (CLUSTER)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1109/CLUSTER49012.2020.00051" rel="external nofollow noopener" target="_blank">10.1109/CLUSTER49012.2020.00051 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:WF5omc3nYNoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Fault tolerance is becoming increasingly important since the probability of permanent hardware failures increases with machine size. A typical resilience approach to fail/stop failures today is checkpointing, which can be performed on system- or application-level. Both levels come in many variants, but they fundamentally differ. On system-level, no code changes are required, full program states are saved, and after a failure the program must be restarted from the last checkpoint. In contrast, on application-level, only user-defined data are check-pointed, which requires some programming effort. Thereby, the running time overhead may be reduced significantly, and programs may continue execution after failures. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerDMTCPCluster20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{System-Level vs. Application-Level Checkpointing}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Cluster Computing (CLUSTER)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{404--405}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CLUSTER49012.2020.00051}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{WF5omc3nYNoC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerSparkPAW18" class="col-sm-8"> <div class="title">Comparison of the HPC and Big Data Java Libraries Spark, PCJ and APGAS</div> <div class="author"> <em>Jonas Posner</em>, Lukas Reitz, and Claudia Fohry </div> <div class="periodical"> <em>In Proceedings International Conference on High Performance Computing, Networking, Storage and Analysis (SC) Workshops (PAW-ATM)</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1109/PAW-ATM.2018.00007" rel="external nofollow noopener" target="_blank">10.1109/PAW-ATM.2018.00007 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:9yKSN-GCB0IC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Although Java is rarely used in HPC, there are a few notable libraries. Use of Java may help to bridge the gap between HPC and big data processing. This paper compares the big data library Spark, and the HPC libraries PCJ and APGAS, regarding productivity and performance. We refer to Java versions of all libraries. For APGAS, we include both the original version and an own extension by locality-flexible tasks. We consider three benchmarks: Calculation of π from HPC, Unbalanced Tree Search (UTS) from HPC, and WordCount from the big data domain. In performance measurements with up to 144 workers, the extended APGAS library was the clear winner. With 144 workers, APGAS programs were up to a factor of more than two faster than Spark programs, and up to about 30% faster than PCJ programs. Regarding productivity, the extended APGAS programs consistently needed the lowest number of different library constructs. Spark ranged second in productivity and PCJ third. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerSparkPAW18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Reitz, Lukas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Comparison of the HPC and Big Data Java Libraries Spark, PCJ and APGAS}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings International Conference on High Performance Computing, Networking, Storage and Analysis (SC) Workshops (PAW-ATM)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{11--22}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/PAW-ATM.2018.00007}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{9yKSN-GCB0IC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="FohryIncrementalHPCS18" class="col-sm-8"> <div class="title">A Selective and Incremental Backup Scheme for Task Pools</div> <div class="author"> Claudia Fohry, <em>Jonas Posner</em>, and Lukas Reitz </div> <div class="periodical"> <em>In Proceedings International Conference on High Performance Computing &amp; Simulation (HPCS)</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1109/HPCS.2018.00103" rel="external nofollow noopener" target="_blank">10.1109/HPCS.2018.00103 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:qjMakFHDy7sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Checkpointing is a common approach to prevent loss of a program’s state after permanent node failures. When it is performed on application-level, less data need to be saved. This paper suggests an uncoordinated application-level checkpointing technique for task pools. It selectively and incrementally saves only those tasks that have stayed in the pool during some period of time and that have not been saved before. The checkpoints are held in a resilient in-memory data store. Our technique applies to any task pool variant in which workers operate at the top of local pools, and work stealing operates at the bottom. Furthermore, the tasks must be free of side effects, and the final result must be calculated by reduction from individual task results. We implemented the technique for the lifeline-based global load balancing variant of task pools. This variant couples random victim selection with an overlay graph for termination detection. A fault-tolerant realization already exists in the form of a Java library, called JFT_GLB. It uses the APGAS and Hazelcast libraries underneath. Our implementation modifies JFT_GLB by replacing its nonselective checkpointing scheme with our new one. In experiments, we compared the overhead of the new scheme to that of JFT_GLB, with UTS, BC and two synthetic benchmarks. The new scheme required slightly more running time when local pools were small, and paid off otherwise. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FohryIncrementalHPCS18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fohry, Claudia and Posner, Jonas and Reitz, Lukas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Selective and Incremental Backup Scheme for Task Pools}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings International Conference on High Performance Computing {\&amp;} Simulation (HPCS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{621--628}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/HPCS.2018.00103}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{qjMakFHDy7sC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerCombinationWLPP18" class="col-sm-8"> <div class="title">A Combination of Intra- and Inter-place Work Stealing for the APGAS Library</div> <div class="author"> <em>Jonas Posner</em>, and Claudia Fohry </div> <div class="periodical"> <em>In Proceedings Parallel Processing and Applied Mathematics (PPAM) Workshops (WLPP)</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1007/978-3-319-78054-2_22" rel="external nofollow noopener" target="_blank">10.1007/978-3-319-78054-2_22 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:UeHWp8X0CEIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Since today’s clusters consist of nodes with multicore processors, modern parallel applications should be able to deal with shared and distributed memory simultaneously. In this paper, we present a novel hybrid work stealing scheme for the APGAS library for Java, which is a branch of the X10 project. Our scheme extends the library’s runtime system, which traditionally performs intra-node work stealing with the Java Fork/Join framework. We add an inter-node work stealing scheme that is inspired by lifeline-based global load balancing. The extended functionality can be accessed from the APGAS library with new constructs. Most important, locality-flexible tasks can be submitted with asyncAny, and are then automatically scheduled over both nodes and cores. In experiments with up to 144 workers on up to 12 nodes, our system achieved near linear speedups for three benchmarks. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerCombinationWLPP18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Combination of Intra- and Inter-place Work Stealing for the APGAS Library}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings Parallel Processing and Applied Mathematics (PPAM) Workshops (WLPP)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{234--243}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-78054-2_22}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{UeHWp8X0CEIC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerFaultToleranceAPDCM17" class="col-sm-8"> <div class="title">Fault Tolerance for Cooperative Lifeline-Based Global Load Balancing in Java with APGAS and Hazelcast</div> <div class="author"> <em>Jonas Posner</em>, and Claudia Fohry </div> <div class="periodical"> <em>In International Parallel and Distributed Processing Symposium (IPDPS) Workshops (APDCM)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1109/ipdpsw.2017.31" rel="external nofollow noopener" target="_blank">10.1109/ipdpsw.2017.31 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:u-x6o8ySG0sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Fault tolerance is a major issue for parallel applications. Approaches on application-level are gaining increasing attention because they may be more efficient than system-level ones. In this paper, we present a generic reusable framework for fault-tolerant parallelization with the task pool pattern. Users of this framework can focus on coding sequential tasks for their problem, while respecting some framework contracts. The framework is written in Java and deploys the APGAS library as well as Hazelcast’s distributed and fault-tolerant IMap. Our fault-tolerance scheme uses two system-wide maps, in which it stores, e.g., backups of local task pools. Framework users may configure the number of backup copies to control how many simultaneous failures are tolerated. The algorithm is correct in the sense that the computed result is the same as in non-failure case, or the program aborts with an error message. In experiments with up to 128 workers, we compared the framework’s performance with that of a non-fault-tolerant variant during failure-free operation. For the UTS and BC benchmarks, the overhead was at most 35%. Measured values were similar as for a related, but less flexible fault-tolerant X10 framework, without a clear winner. Raising the number of backup copies to six only marginally improved the overhead. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerFaultToleranceAPDCM17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fault Tolerance for Cooperative Lifeline-Based Global Load Balancing in Java with APGAS and Hazelcast}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Parallel and Distributed Processing Symposium (IPDPS) Workshops (APDCM)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{854--863}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ipdpsw.2017.31}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{u-x6o8ySG0sC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerCooperationX1016" class="col-sm-8"> <div class="title">Cooperation vs. Coordination for Lifeline-Based Global Load Balancing in APGAS</div> <div class="author"> <em>Jonas Posner</em>, and Claudia Fohry </div> <div class="periodical"> <em>In Proceedings of the 6th ACM SIGPLAN Workshop on X10</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1145/2931028.2931029" rel="external nofollow noopener" target="_blank">10.1145/2931028.2931029 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:zYLM7Y9cAGgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Work stealing can be implemented in either a cooperative or a coordinated way. We compared the two approaches for lifeline-based global load balancing, which is the algorithm used by X10’s Global Load Balancing framework GLB. We conducted our study with the APGAS library for Java, to which we ported GLB in a first step. Our cooperative variant resembles the original GLB framework, except that strict sequentialization is replaced by Java synchronization constructs such as critical sections. Our coordinated variant enables concurrent access to local task pools by using a split queue data structure. In experiments with modified versions of the UTS and BC benchmarks, the cooperative and coordinated APGAS variants had similar executions times, without a clear winner. Both variants outperformed the original GLB when compiled with Managed X10. Experiments were run on up to 128 nodes, to which we assigned up to 512 places. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PosnerCooperationX1016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Fohry, Claudia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cooperation vs. Coordination for Lifeline-Based Global Load Balancing in APGAS}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 6th ACM SIGPLAN Workshop on X10}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{13--17}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2931028.2931029}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{zYLM7Y9cAGgC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="FohryFaultToleranceX1015" class="col-sm-8"> <div class="title">Towards an Efficient Fault-Tolerance Scheme for GLB</div> <div class="author"> Claudia Fohry, Marco Bungart, and <em>Jonas Posner</em> </div> <div class="periodical"> <em>In Proceedings of the ACM SIGPLAN Workshop on X10</em>, 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1145/2771774.2771779" rel="external nofollow noopener" target="_blank">10.1145/2771774.2771779 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:YsMSGLbcyi4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> X10’s Global Load Balancing framework GLB implements a user-level task pool for inter-place load balancing. It is based on work stealing and deploys the lifeline algorithm. A single worker per place alternates between processing tasks and answering steal requests. We have devised an efficient fault-tolerance scheme for this algorithm, improving on a simpler resilience scheme from our own previous work. Among the base ideas of the new scheme are incremental backups of “stable” tasks and an actor-like communication structure. The paper reports on our ongoing work to extend the GLB framework accordingly. While details of the scheme are left out, we discuss implementation issues and preliminary experimental results. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FohryFaultToleranceX1015</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fohry, Claudia and Bungart, Marco and Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards an Efficient Fault-Tolerance Scheme for GLB}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the ACM SIGPLAN Workshop on X10}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{27--32}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2771774.2771779}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{YsMSGLbcyi4C}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="BungartFaultToleranceSYNASC14" class="col-sm-8"> <div class="title">Fault-Tolerant Global Load Balancing in X10</div> <div class="author"> Marco Bungart, Claudia Fohry, and <em>Jonas Posner</em> </div> <div class="periodical"> <em>In Proceedings International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)</em>, 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1109/synasc.2014.69" rel="external nofollow noopener" target="_blank">10.1109/synasc.2014.69 </a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N2ODCCEAAAAJ&amp;citation_for_view=N2ODCCEAAAAJ:W7OEmFMy1HYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p> Scalability postulates fault tolerance to be effective. We consider a user-level fault tolerance technique to cope with permanent node failures. It is supported by X10, one of the major Partitioned Global Address Space (PGAS) languages. In Resilient X10, an exception is thrown when a place (node) fails. This paper investigates task pools, which are often used by irregular applications to balance their load. We consider global load balancing with one worker per place. Each worker maintains a private task pool and supports cooperative work stealing. Tasks may generate new tasks dynamically, are free of side-effects, and their results are combined by reduction. Our first contribution is a task pool algorithm that can handle permanent place failures. It is based on snapshots that are regularly written to other workers and are updated in the event of stealing. Second, we implemented the algorithm in the Global Load Balancing framework GLB, which is part of the standard library of X10. We ran experiments with the Unbalanced Tree Search (UTS) and Between ness Centrality (BC) benchmarks. With 64 places on 4 nodes, for instance, we observed an overhead of about 4% for using fault-tolerant GLB instead of GLB. The protocol overhead for a place failure was neglectable. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BungartFaultToleranceSYNASC14</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bungart, Marco and Fohry, Claudia and Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fault-Tolerant Global Load Balancing in X10}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{471--478}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/synasc.2014.69}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{W7OEmFMy1HYC}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <a id="Posters and Extended Abstracts"></a> <p class="bibtitle">Posters and Extended Abstracts</p> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ResAdapPAW24" class="col-sm-8"> <div class="title">Resource Adaptivity at Task-Level</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>At Parallel Applications Workshop, Alternatives To MPI+X (PAW-ATM)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.5281/zenodo.14211666" rel="external nofollow noopener" target="_blank">10.5281/zenodo.14211666 </a> <a href="https://doi.org/10.5281/zenodo.14176767" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@conference</span><span class="p">{</span><span class="nl">ResAdapPAW24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Resource Adaptivity at Task-Level}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Parallel Applications Workshop, Alternatives To MPI+X (PAW-ATM)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">addendum</span> <span class="p">=</span> <span class="s">{Extended Abstract}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.14211666}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerWagomuISC24" class="col-sm-8"> <div class="title">Project Wagomu: Elastic HPC Resource Management</div> <div class="author"> <em>Jonas Posner</em>, and Patrick Finnerty </div> <div class="periodical"> <em>At ISC High Performance Conference</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://uni-kassel.de/go/isc24" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@conference</span><span class="p">{</span><span class="nl">PosnerWagomuISC24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas and Finnerty, Patrick}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Project Wagomu: Elastic HPC Resource Management}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ISC High Performance Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerAMTSC22" class="col-sm-8"> <div class="title">Load Balancing, Fault Tolerance, and Resource Elasticity for Asynchronous Many-Task Systems</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>At International Conference on High Performance Computing, Networking, Storage and Analysis (SC)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.uni-kassel.de/eecs/plm/team/jonas-posner/sc22" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@conference</span><span class="p">{</span><span class="nl">PosnerAMTSC22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Load Balancing, Fault Tolerance, and Resource Elasticity for Asynchronous Many-Task Systems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on High Performance Computing, Networking, Storage and Analysis (SC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerAMTISC22" class="col-sm-8"> <div class="title">Asynchronous Many-Tasking (AMT): Load Balancing, Fault Tolerance, Resource Elasticity</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>At ISC High Performance Conference</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.uni-kassel.de/eecs/plm/team/jonas-posner/isc22" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@conference</span><span class="p">{</span><span class="nl">PosnerAMTISC22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Asynchronous Many-Tasking (AMT): Load Balancing, Fault Tolerance, Resource Elasticity}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ISC High Performance Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerElasticity21" class="col-sm-8"> <div class="title">Resource Elasticity at Task-Level</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>At Proceedings International Parallel and Distributed Processing Symposium (IPDPS), Ph.D. Forum</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> doi:<a href="https://doi.org/10.1109/IPDPSW52791.2021.00160" rel="external nofollow noopener" target="_blank">10.1109/IPDPSW52791.2021.00160 </a> <a href="https://www.uni-kassel.de/eecs/plm/team/jonas-posner/resource-elasticity-at-task-level" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@conference</span><span class="p">{</span><span class="nl">PosnerElasticity21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Resource Elasticity at Task-Level}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings International Parallel and Distributed Processing Symposium (IPDPS), Ph.D. Forum}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IPDPSW52791.2021.00160}</span><span class="p">,</span>
  <span class="na">addendum</span> <span class="p">=</span> <span class="s">{Extended Abstract}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerLocalityPrace21" class="col-sm-8"> <div class="title">Locality-Flexible and Cancelable Tasks for the APGAS Library</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>At EuroHPC Summit Week, PRACEdays</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.uni-kassel.de/go/EuroHPC20" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@conference</span><span class="p">{</span><span class="nl">PosnerLocalityPrace21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Locality-Flexible and Cancelable Tasks for the APGAS Library}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{EuroHPC Summit Week, PRACEdays}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="PosnerFaultToleranceIPDPS17" class="col-sm-8"> <div class="title">A Generic Reusable Java Framework for Fault-Tolerant Parallelization with the Task Pool Pattern</div> <div class="author"> <em>Jonas Posner</em> </div> <div class="periodical"> <em>At International Parallel and Distributed Processing Symposium (IPDPS), Ph.D. Forum</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.uni-kassel.de/eecs/?id=46913" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@conference</span><span class="p">{</span><span class="nl">PosnerFaultToleranceIPDPS17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Posner, Jonas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Generic Reusable Java Framework for Fault-Tolerant Parallelization with the Task Pool Pattern}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Parallel and Distributed Processing Symposium (IPDPS), Ph.D. Forum}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jonas Posner. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: April 13, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>